{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b20c26",
   "metadata": {},
   "source": [
    "# References\n",
    "- [SumTree introduction in Python](https://adventuresinmachinelearning.com/sumtree-introduction-python/)\n",
    "- [A Deeper Look at Experience Replay](https://arxiv.org/abs/1712.01275)\n",
    "- [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)\n",
    "- [Double Learning and Prioritized Experience Replay](https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/)\n",
    "- [GitHub rlcode: Prioritized Experience Replay](https://github.com/rlcode/per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06758b41",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838f3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "from gym import logger\n",
    "logger.set_level(gym.logger.DISABLED)\n",
    "from replay_buffer import ReplayBuffer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488ed8f0",
   "metadata": {},
   "source": [
    "# Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b7512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree:\n",
    "    write = 0\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.n_entries = 0\n",
    "    \n",
    "    # update to the root node\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "        \n",
    "        self.tree[parent] += change\n",
    "        \n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "    \n",
    "    # find sample on leaf node\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "        \n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "            #return min(idx, self.n_entries + self.capacity - 2) # idx can be greater than n_entries + capacity - 2 which means dataIdx >= n_entries\n",
    "        \n",
    "        if s < self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "    \n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "    \n",
    "    # store priority and sample\n",
    "    def add(self, p, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "        \n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, p)\n",
    "        \n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "        \n",
    "        if self.n_entries < self.capacity:\n",
    "            self.n_entries += 1\n",
    "    \n",
    "    # update priority\n",
    "    def update(self, idx, p):\n",
    "        change = p - self.tree[idx]\n",
    "        \n",
    "        self.tree[idx] = p\n",
    "        self._propagate(idx, change)\n",
    "    \n",
    "    # get priority and sample\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        dataIdx = idx - self.capacity + 1\n",
    "        \n",
    "        return (idx, self.tree[idx], self.data[dataIdx])\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "    \n",
    "class ReplayBuffer:\n",
    "    e = 0.01\n",
    "    a = 0.6\n",
    "    beta = 0.4\n",
    "    beta_increment_per_sampling = 0.001\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(int(capacity))\n",
    "        self.capacity = int(capacity)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.tree.n_entries\n",
    "    \n",
    "    def _get_priority(self, error):\n",
    "        return (np.abs(error) + self.e) ** self.a\n",
    "    \n",
    "    def add(self, error, sample):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.add(p, Transition(*sample))\n",
    "    \n",
    "    def sample(self, n):\n",
    "        batch = []\n",
    "        idxs = []\n",
    "        segment = self.tree.total() / n\n",
    "        priorities = []\n",
    "        \n",
    "        self.beta = np.min([1, self.beta + self.beta_increment_per_sampling])\n",
    "        \n",
    "        for i in range(n):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            \n",
    "            s = random.uniform(a, b)\n",
    "            idx, p, data = self.tree.get(s)\n",
    "            priorities.append(p)\n",
    "            batch.append(data)\n",
    "            idxs.append(idx)\n",
    "        \n",
    "        sampling_probabilities = priorities / self.tree.total()\n",
    "        is_weight = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
    "        is_weight /= is_weight.max()\n",
    "        \n",
    "        return batch, idxs, is_weight\n",
    "    \n",
    "    def update(self, idx, error):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.update(idx, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ccb946",
   "metadata": {},
   "source": [
    "# CartPole Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f6b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bbbcce",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9817958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e41dc",
   "metadata": {},
   "source": [
    "# DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ee9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, config, nn):\n",
    "        self.step = 0\n",
    "        self.gamma = config[\"gamma\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        self.replay_buffer = ReplayBuffer(config[\"buffer_size\"])\n",
    "        self.n_gradient_steps = config[\"n_gradient_steps\"]\n",
    "        self.n_actions = config[\"n_actions\"]\n",
    "        self.epsilon = config[\"epsilon_max\"]\n",
    "        self.epsilon_max = config[\"epsilon_max\"]\n",
    "        self.epsilon_min = config[\"epsilon_min\"]\n",
    "        self.epsilon_decay = config[\"epsilon_decay\"]\n",
    "        self.nn = nn.to(device)\n",
    "        self.target_nn = deepcopy(self.nn).to(device)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.optimizer = optim.RMSprop(self.nn.parameters(), lr=config[\"learning_rate\"])\n",
    "        self.option = config[\"option\"]\n",
    "        if \"beta\" in config:\n",
    "            self.beta = config[\"beta\"]\n",
    "            self.update_target_nn = self.smooth_update_target_nn\n",
    "        elif \"C\" in config:\n",
    "            self.C = config[\"C\"]\n",
    "            self.update_target_nn = self.periodic_update_target_nn\n",
    "        else:\n",
    "            self.update_target_nn = (lambda: None)\n",
    "            self.option = 0\n",
    "    \n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        state_action_values = self.nn(state.unsqueeze(0)).gather(1, action.unsqueeze(0))\n",
    "        if self.option == 2:\n",
    "            # Double Q-Learning\n",
    "            next_state_action_values = self.target_nn(next_state.unsqueeze(0)).gather(1, self.nn(next_state.unsqueeze(0)).max(1)[1].unsqueeze(1)).detach()\n",
    "        elif self.option == 1:\n",
    "            # Target\n",
    "            next_state_action_values = self.target_nn(next_state.unsqueeze(0)).max(1)[0].unsqueeze(1).detach()\n",
    "        else:\n",
    "            # Vanilla\n",
    "            next_state_action_values = self.nn(next_state.unsqueeze(0)).max(1)[0].unsqueeze(1).detach()\n",
    "        expected_state_action_values = reward.unsqueeze(0) + self.gamma * next_state_action_values * (1 - done.unsqueeze(0))\n",
    "        error = torch.abs(state_action_values - expected_state_action_values).data.numpy()\n",
    "        \n",
    "        self.replay_buffer.add(error, (state, action, reward, next_state, done))\n",
    "    \n",
    "    def update_epsilon(self):\n",
    "        self.epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * math.exp(-1. * self.step / self.epsilon_decay)\n",
    "    \n",
    "    def epsilon_greedy_action(self, state):\n",
    "        if random.random() > self.epsilon:\n",
    "            with torch.no_grad():\n",
    "                return torch.argmax(self.nn(torch.Tensor(state))).item()\n",
    "        else:\n",
    "            return torch.tensor(random.randrange(self.n_actions), device=device, dtype=torch.long).item()\n",
    "    \n",
    "    def greedy_action(self, state):\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax(self.nn(torch.Tensor(state))).item()\n",
    "    \n",
    "    def gradient_step(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        transitions, idxs, is_weights = self.replay_buffer.sample(self.batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.stack(batch.action)\n",
    "        reward_batch = torch.stack(batch.reward)\n",
    "        next_state_batch = torch.stack(batch.next_state)\n",
    "        done_batch = torch.stack(batch.done)\n",
    "        \n",
    "        state_action_values = self.nn(state_batch).gather(1, action_batch)\n",
    "        if self.option == 2:\n",
    "            # Double Q-Learning\n",
    "            next_state_action_values = self.target_nn(next_state_batch).gather(1, self.nn(next_state_batch).max(1)[1].unsqueeze(1)).detach()\n",
    "        elif self.option == 1:\n",
    "            # Target\n",
    "            next_state_action_values = self.target_nn(next_state_batch).max(1)[0].unsqueeze(1).detach()\n",
    "        else:\n",
    "            # Vanilla\n",
    "            next_state_action_values = self.nn(next_state_batch).max(1)[0].unsqueeze(1).detach()\n",
    "        expected_state_action_values = reward_batch + self.gamma * next_state_action_values * (1 - done_batch)\n",
    "        \n",
    "        errors = torch.abs(state_action_values - expected_state_action_values).data.numpy()\n",
    "        for i in range(self.batch_size):\n",
    "            idx = idxs[i]\n",
    "            self.replay_buffer.update(idx, errors[i])\n",
    "        \n",
    "        loss = self.criterion(state_action_values, expected_state_action_values)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.update_target_nn()\n",
    "    \n",
    "    def periodic_update_target_nn(self):\n",
    "        if self.step % self.C == 0:\n",
    "            self.target_nn.load_state_dict(self.nn.state_dict())  \n",
    "    \n",
    "    def smooth_update_target_nn(self):\n",
    "        for param_nn, param_target_nn in zip(self.nn.parameters(), self.target_nn.parameters()):\n",
    "            param_target_nn.data.copy_(param_nn * self.beta + param_target_nn * (1 - self.beta))\n",
    "    \n",
    "    def train(self, env, n_episodes):\n",
    "        episode_return_list = []\n",
    "        for i_episode in range(1, n_episodes+1):\n",
    "            episode_return = 0\n",
    "            state = env.reset()\n",
    "            for t in count():\n",
    "                self.update_epsilon()\n",
    "                action = self.epsilon_greedy_action(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                episode_return += reward\n",
    "                \n",
    "                self.append_sample(torch.Tensor(state), torch.tensor([action], dtype=torch.long), torch.tensor([reward], dtype=torch.float), torch.Tensor(next_state), torch.tensor([int(done)], dtype=torch.long))\n",
    "                state = next_state\n",
    "                self.step += 1\n",
    "                \n",
    "                for _ in range(self.n_gradient_steps):\n",
    "                    self.gradient_step()\n",
    "                \n",
    "                if done:\n",
    "                    episode_return_list.append(episode_return)\n",
    "                    print(\"Episode {:4d} : {:4d} steps | epsilon = {:4.2f} | return = {:.1f}\".format(i_episode, t+1, self.epsilon, episode_return))\n",
    "                    break\n",
    "        return episode_return_list\n",
    "    \n",
    "    def test(self, env, step_max):\n",
    "        episode_return = 0\n",
    "        state = env.reset()\n",
    "        for t in count():\n",
    "            env.render()\n",
    "            action = self.greedy_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode_return += reward\n",
    "            \n",
    "            state = next_state\n",
    "\n",
    "            if done or t+1 >= step_max:\n",
    "                env.close()\n",
    "                return episode_return\n",
    "    \n",
    "    def save(self, name):\n",
    "        torch.save(self.nn.state_dict(), \"trained_nn/{}.pt\".format(name))\n",
    "    \n",
    "    def load(self, name):\n",
    "        self.nn.load_state_dict(torch.load(\"trained_nn/{}.pt\".format(name)))\n",
    "\n",
    "config = {\"gamma\": 0.95,\n",
    "          \"batch_size\": 8,\n",
    "          \"buffer_size\": 1e6,\n",
    "          \"n_gradient_steps\": 1,\n",
    "          \"n_actions\": 2,\n",
    "          \"learning_rate\": 0.001,\n",
    "          \"epsilon_max\": 1.,\n",
    "          \"epsilon_min\": 0.01,\n",
    "          \"epsilon_decay\": 5000,\n",
    "          \"C\": 100,\n",
    "          \"option\": 1}\n",
    "\n",
    "dqn = DQN()\n",
    "agent = Agent(config, dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac08c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode    1 :   29 steps | epsilon = 0.99 | return = 29.0\n",
      "Episode    2 :   26 steps | epsilon = 0.99 | return = 26.0\n",
      "Episode    3 :   21 steps | epsilon = 0.99 | return = 21.0\n",
      "Episode    4 :   13 steps | epsilon = 0.98 | return = 13.0\n",
      "Episode    5 :   13 steps | epsilon = 0.98 | return = 13.0\n",
      "Episode    6 :   42 steps | epsilon = 0.97 | return = 42.0\n",
      "Episode    7 :   12 steps | epsilon = 0.97 | return = 12.0\n",
      "Episode    8 :   28 steps | epsilon = 0.96 | return = 28.0\n",
      "Episode    9 :   23 steps | epsilon = 0.96 | return = 23.0\n",
      "Episode   10 :   21 steps | epsilon = 0.96 | return = 21.0\n",
      "Episode   11 :   24 steps | epsilon = 0.95 | return = 24.0\n",
      "Episode   12 :   22 steps | epsilon = 0.95 | return = 22.0\n",
      "Episode   13 :   71 steps | epsilon = 0.93 | return = 71.0\n",
      "Episode   14 :   15 steps | epsilon = 0.93 | return = 15.0\n",
      "Episode   15 :   11 steps | epsilon = 0.93 | return = 11.0\n",
      "Episode   16 :   26 steps | epsilon = 0.92 | return = 26.0\n",
      "Episode   17 :   12 steps | epsilon = 0.92 | return = 12.0\n",
      "Episode   18 :   20 steps | epsilon = 0.92 | return = 20.0\n",
      "Episode   19 :   48 steps | epsilon = 0.91 | return = 48.0\n",
      "Episode   20 :   19 steps | epsilon = 0.91 | return = 19.0\n",
      "Episode   21 :   10 steps | epsilon = 0.90 | return = 10.0\n",
      "Episode   22 :   28 steps | epsilon = 0.90 | return = 28.0\n",
      "Episode   23 :   23 steps | epsilon = 0.90 | return = 23.0\n",
      "Episode   24 :   17 steps | epsilon = 0.89 | return = 17.0\n",
      "Episode   25 :   37 steps | epsilon = 0.89 | return = 37.0\n",
      "Episode   26 :   26 steps | epsilon = 0.88 | return = 26.0\n",
      "Episode   27 :   23 steps | epsilon = 0.88 | return = 23.0\n",
      "Episode   28 :   42 steps | epsilon = 0.87 | return = 42.0\n",
      "Episode   29 :   19 steps | epsilon = 0.87 | return = 19.0\n",
      "Episode   30 :   11 steps | epsilon = 0.87 | return = 11.0\n",
      "Episode   31 :   11 steps | epsilon = 0.86 | return = 11.0\n",
      "Episode   32 :   20 steps | epsilon = 0.86 | return = 20.0\n",
      "Episode   33 :   12 steps | epsilon = 0.86 | return = 12.0\n",
      "Episode   34 :   14 steps | epsilon = 0.86 | return = 14.0\n",
      "Episode   35 :   23 steps | epsilon = 0.85 | return = 23.0\n",
      "Episode   36 :   13 steps | epsilon = 0.85 | return = 13.0\n",
      "Episode   37 :   42 steps | epsilon = 0.84 | return = 42.0\n",
      "Episode   38 :   22 steps | epsilon = 0.84 | return = 22.0\n",
      "Episode   39 :   23 steps | epsilon = 0.84 | return = 23.0\n",
      "Episode   40 :   18 steps | epsilon = 0.83 | return = 18.0\n",
      "Episode   41 :   28 steps | epsilon = 0.83 | return = 28.0\n",
      "Episode   42 :   12 steps | epsilon = 0.83 | return = 12.0\n",
      "Episode   43 :   15 steps | epsilon = 0.82 | return = 15.0\n",
      "Episode   44 :   12 steps | epsilon = 0.82 | return = 12.0\n",
      "Episode   45 :   16 steps | epsilon = 0.82 | return = 16.0\n",
      "Episode   46 :   33 steps | epsilon = 0.81 | return = 33.0\n",
      "Episode   47 :   16 steps | epsilon = 0.81 | return = 16.0\n",
      "Episode   48 :   74 steps | epsilon = 0.80 | return = 74.0\n",
      "Episode   49 :   64 steps | epsilon = 0.79 | return = 64.0\n",
      "Episode   50 :   30 steps | epsilon = 0.78 | return = 30.0\n",
      "Episode   51 :   50 steps | epsilon = 0.78 | return = 50.0\n",
      "Episode   52 :   31 steps | epsilon = 0.77 | return = 31.0\n",
      "Episode   53 :   33 steps | epsilon = 0.77 | return = 33.0\n",
      "Episode   54 :   22 steps | epsilon = 0.76 | return = 22.0\n",
      "Episode   55 :   22 steps | epsilon = 0.76 | return = 22.0\n",
      "Episode   56 :   26 steps | epsilon = 0.76 | return = 26.0\n",
      "Episode   57 :   12 steps | epsilon = 0.75 | return = 12.0\n",
      "Episode   58 :   39 steps | epsilon = 0.75 | return = 39.0\n",
      "Episode   59 :   13 steps | epsilon = 0.75 | return = 13.0\n",
      "Episode   60 :   28 steps | epsilon = 0.74 | return = 28.0\n",
      "Episode   61 :   31 steps | epsilon = 0.74 | return = 31.0\n",
      "Episode   62 :   12 steps | epsilon = 0.74 | return = 12.0\n",
      "Episode   63 :   34 steps | epsilon = 0.73 | return = 34.0\n",
      "Episode   64 :   24 steps | epsilon = 0.73 | return = 24.0\n",
      "Episode   65 :   20 steps | epsilon = 0.73 | return = 20.0\n",
      "Episode   66 :   11 steps | epsilon = 0.72 | return = 11.0\n",
      "Episode   67 :   52 steps | epsilon = 0.72 | return = 52.0\n",
      "Episode   68 :   57 steps | epsilon = 0.71 | return = 57.0\n",
      "Episode   69 :   45 steps | epsilon = 0.70 | return = 45.0\n",
      "Episode   70 :   15 steps | epsilon = 0.70 | return = 15.0\n",
      "Episode   71 :   63 steps | epsilon = 0.69 | return = 63.0\n",
      "Episode   72 :   22 steps | epsilon = 0.69 | return = 22.0\n",
      "Episode   73 :   64 steps | epsilon = 0.68 | return = 64.0\n",
      "Episode   74 :   16 steps | epsilon = 0.68 | return = 16.0\n",
      "Episode   75 :   35 steps | epsilon = 0.67 | return = 35.0\n",
      "Episode   76 :   32 steps | epsilon = 0.67 | return = 32.0\n",
      "Episode   77 :   30 steps | epsilon = 0.66 | return = 30.0\n",
      "Episode   78 :   53 steps | epsilon = 0.66 | return = 53.0\n",
      "Episode   79 :   22 steps | epsilon = 0.65 | return = 22.0\n",
      "Episode   80 :   19 steps | epsilon = 0.65 | return = 19.0\n",
      "Episode   81 :   55 steps | epsilon = 0.65 | return = 55.0\n",
      "Episode   82 :   41 steps | epsilon = 0.64 | return = 41.0\n",
      "Episode   83 :   79 steps | epsilon = 0.63 | return = 79.0\n",
      "Episode   84 :   62 steps | epsilon = 0.62 | return = 62.0\n",
      "Episode   85 :   47 steps | epsilon = 0.62 | return = 47.0\n",
      "Episode   86 :   19 steps | epsilon = 0.61 | return = 19.0\n",
      "Episode   87 :   53 steps | epsilon = 0.61 | return = 53.0\n",
      "Episode   88 :   22 steps | epsilon = 0.61 | return = 22.0\n",
      "Episode   89 :   98 steps | epsilon = 0.59 | return = 98.0\n",
      "Episode   90 :   56 steps | epsilon = 0.59 | return = 56.0\n",
      "Episode   91 :   35 steps | epsilon = 0.58 | return = 35.0\n",
      "Episode   92 :   20 steps | epsilon = 0.58 | return = 20.0\n",
      "Episode   93 :   40 steps | epsilon = 0.58 | return = 40.0\n",
      "Episode   94 :   60 steps | epsilon = 0.57 | return = 60.0\n",
      "Episode   95 :   49 steps | epsilon = 0.56 | return = 49.0\n",
      "Episode   96 :   90 steps | epsilon = 0.55 | return = 90.0\n",
      "Episode   97 :   83 steps | epsilon = 0.55 | return = 83.0\n",
      "Episode   98 :  124 steps | epsilon = 0.53 | return = 124.0\n",
      "Episode   99 :   31 steps | epsilon = 0.53 | return = 31.0\n",
      "Episode  100 :  229 steps | epsilon = 0.51 | return = 229.0\n"
     ]
    }
   ],
   "source": [
    "episode_return_list = agent.train(env, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4302c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleSwingUp(gym.Wrapper):\n",
    "    def __init__(self, env, **kwargs):\n",
    "        super(CartPoleSwingUp, self).__init__(env, **kwargs)\n",
    "        self.theta_dot_threshold = 4*np.pi\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.env.state = [0, 0, np.pi, 0] + super().reset()\n",
    "        self.env.env.steps_beyond_done = None\n",
    "        return np.array(self.env.env.state)\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, done, _ = super().step(action)\n",
    "        x, x_dot, theta, theta_dot = state\n",
    "        \n",
    "        done = x < -self.x_threshold \\\n",
    "               or x > self.x_threshold \\\n",
    "               or theta_dot < -self.theta_dot_threshold \\\n",
    "               or theta_dot > self.theta_dot_threshold\n",
    "        \n",
    "        if done:\n",
    "            # game over\n",
    "            reward = -10.\n",
    "            if self.steps_beyond_done is None:\n",
    "                self.steps_beyond_done = 0\n",
    "            else:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "                self.steps_beyond_done += 1\n",
    "        else:\n",
    "            if -self.theta_threshold_radians < theta and theta < self.theta_threshold_radians:\n",
    "                # pole upright\n",
    "                reward = 1.\n",
    "            else:\n",
    "                # pole swinging\n",
    "                reward = 0.\n",
    "\n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "env = CartPoleSwingUp(gym.make('CartPole-v1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbe7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"gamma\": 0.95,\n",
    "          \"batch_size\": 64,\n",
    "          \"buffer_size\": 1e6,\n",
    "          \"n_gradient_steps\": 1,\n",
    "          \"n_actions\": 2,\n",
    "          \"learning_rate\": 0.001,\n",
    "          \"epsilon_max\": 1.,\n",
    "          \"epsilon_min\": 0.01,\n",
    "          \"epsilon_decay\": 5000,\n",
    "          \"C\": 100,\n",
    "          \"option\": 2}\n",
    "\n",
    "dqn = DQN()\n",
    "agent = Agent(config, dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7556536d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode    1 :  387 steps | epsilon = 0.93 | return = -10.0\n",
      "Episode    2 :  193 steps | epsilon = 0.89 | return = -10.0\n",
      "Episode    3 :   89 steps | epsilon = 0.88 | return = -10.0\n",
      "Episode    4 :  128 steps | epsilon = 0.85 | return = -10.0\n",
      "Episode    5 :  175 steps | epsilon = 0.83 | return = -10.0\n",
      "Episode    6 :   53 steps | epsilon = 0.82 | return = -10.0\n",
      "Episode    7 :  151 steps | epsilon = 0.79 | return = -10.0\n",
      "Episode    8 :   57 steps | epsilon = 0.78 | return = -10.0\n",
      "Episode    9 :   99 steps | epsilon = 0.77 | return = -10.0\n",
      "Episode   10 :  156 steps | epsilon = 0.75 | return = -10.0\n",
      "Episode   11 :   67 steps | epsilon = 0.74 | return = -10.0\n",
      "Episode   12 :   94 steps | epsilon = 0.72 | return = -10.0\n",
      "Episode   13 :   95 steps | epsilon = 0.71 | return = -10.0\n",
      "Episode   14 :  252 steps | epsilon = 0.67 | return = -10.0\n",
      "Episode   15 :  134 steps | epsilon = 0.66 | return = -10.0\n",
      "Episode   16 :  200 steps | epsilon = 0.63 | return = -10.0\n",
      "Episode   17 :  302 steps | epsilon = 0.59 | return = -10.0\n",
      "Episode   18 :  487 steps | epsilon = 0.54 | return = -10.0\n",
      "Episode   19 : 1837 steps | epsilon = 0.38 | return = -6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/rl/lib/python3.7/site-packages/ipykernel_launcher.py:105: RuntimeWarning: divide by zero encountered in power\n",
      "/home/max/anaconda3/envs/rl/lib/python3.7/site-packages/ipykernel_launcher.py:106: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zip argument #64 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-33b20683601a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepisode_return_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-b7ade91dc67f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env, n_episodes)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b7ade91dc67f>\u001b[0m in \u001b[0;36mgradient_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mstate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #64 must support iteration"
     ]
    }
   ],
   "source": [
    "episode_return_list = agent.train(env, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d4f6f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406.2579345703125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer.tree.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c5ae605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5046"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer.tree.n_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "316fb7a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer.tree.capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b0e635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005044,\n",
       " 0.3313210606575012,\n",
       " Transition(state=tensor([-0.2161,  0.5510,  4.0701,  1.3220]), action=tensor([1]), reward=tensor([0.]), next_state=tensor([-0.2051,  0.7295,  4.0966,  1.2470]), done=tensor([0])))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer.tree.get(agent.replay_buffer.tree.total() - 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4f8938e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10779391974210739\n",
      "0.4694114625453949\n",
      "0.40345054864883423\n",
      "0.3975670337677002\n",
      "0.35289648175239563\n",
      "0.25959840416908264\n",
      "0.37099429965019226\n",
      "0.37603694200515747\n",
      "0.4159894585609436\n",
      "0.5031104683876038\n",
      "0.6805336475372314\n",
      "0.7422857284545898\n",
      "0.6383516788482666\n",
      "0.2833240330219269\n",
      "0.4410078227519989\n",
      "0.3239527642726898\n",
      "0.4206015169620514\n",
      "0.46233949065208435\n",
      "0.5516879558563232\n",
      "0.28144407272338867\n",
      "0.342303991317749\n",
      "0.7345882654190063\n",
      "0.6751468181610107\n",
      "0.24015632271766663\n",
      "0.18442586064338684\n",
      "0.2297784984111786\n",
      "0.07366155833005905\n",
      "0.144300639629364\n",
      "0.07827139645814896\n",
      "0.3701689839363098\n",
      "0.5057386159896851\n",
      "0.2772115468978882\n",
      "0.4427688419818878\n",
      "0.11088944226503372\n",
      "0.14837409555912018\n",
      "0.3371681571006775\n",
      "0.3454602360725403\n",
      "0.33757418394088745\n",
      "0.2057182639837265\n",
      "0.3177955448627472\n",
      "0.19138458371162415\n",
      "0.24309928715229034\n",
      "0.3079693615436554\n",
      "0.30093249678611755\n",
      "0.10048722475767136\n",
      "0.5821244120597839\n",
      "0.23987500369548798\n",
      "0.08279425650835037\n",
      "0.10048987716436386\n",
      "0.06896474957466125\n",
      "0.2923209071159363\n",
      "0.5138850212097168\n",
      "0.14815713465213776\n",
      "0.250370055437088\n",
      "0.12568625807762146\n",
      "0.29807063937187195\n",
      "0.46285930275917053\n",
      "0.4252319931983948\n",
      "0.14435029029846191\n",
      "0.5161372423171997\n",
      "0.27987948060035706\n",
      "0.0847129300236702\n",
      "0.14253227412700653\n",
      "0.44609570503234863\n",
      "0.3364337980747223\n",
      "0.3495110273361206\n",
      "0.6568397879600525\n",
      "0.3637097179889679\n",
      "0.21060682833194733\n",
      "0.3226119577884674\n",
      "0.47175973653793335\n",
      "0.4551493227481842\n",
      "0.4213503897190094\n",
      "0.4962363541126251\n",
      "0.5440413355827332\n",
      "0.377310186624527\n",
      "0.2538367807865143\n",
      "0.5389819145202637\n",
      "0.2820793092250824\n",
      "0.18305420875549316\n",
      "0.22160063683986664\n",
      "0.6577233076095581\n",
      "0.31195273995399475\n",
      "0.7286019325256348\n",
      "0.06700152158737183\n",
      "0.14079169929027557\n",
      "0.2682943642139435\n",
      "0.5412486791610718\n",
      "0.37066224217414856\n",
      "0.25407111644744873\n",
      "0.20477689802646637\n",
      "0.642806887626648\n",
      "0.3444938361644745\n",
      "0.33517390489578247\n",
      "0.4195299446582794\n",
      "0.47176221013069153\n",
      "0.6231129169464111\n",
      "0.5282403230667114\n",
      "0.41798004508018494\n",
      "0.5055617094039917\n",
      "0.8069865107536316\n",
      "0.7313300967216492\n",
      "0.9310330152511597\n",
      "0.48821574449539185\n",
      "0.601642370223999\n",
      "0.666353166103363\n",
      "0.10187894105911255\n",
      "0.36060193181037903\n",
      "0.7100600004196167\n",
      "0.31605464220046997\n",
      "0.9131921529769897\n",
      "0.7439391016960144\n",
      "1.4823485612869263\n",
      "1.4823485612869263\n",
      "1.4879223108291626\n",
      "1.4879223108291626\n",
      "0.09013084322214127\n",
      "0.21659129858016968\n",
      "0.4660159945487976\n",
      "0.17427575588226318\n",
      "0.27892404794692993\n",
      "0.1262083351612091\n",
      "0.3048858046531677\n",
      "0.397028386592865\n",
      "0.23155751824378967\n",
      "0.28987058997154236\n",
      "0.6373517513275146\n",
      "0.445735365152359\n",
      "0.5543459057807922\n",
      "0.13001631200313568\n",
      "0.43116769194602966\n",
      "0.13997916877269745\n",
      "0.15051652491092682\n",
      "0.22493402659893036\n",
      "0.5033032894134521\n",
      "0.735528826713562\n",
      "0.2900030016899109\n",
      "0.6424534916877747\n",
      "0.5107256770133972\n",
      "1.0247251987457275\n",
      "0.08122541755437851\n",
      "0.6592503786087036\n",
      "0.30602437257766724\n",
      "0.09656071662902832\n",
      "0.1531154364347458\n",
      "0.20727820694446564\n",
      "0.20634199678897858\n",
      "0.25105929374694824\n",
      "0.36300697922706604\n",
      "0.4965686798095703\n",
      "0.4158308207988739\n",
      "0.07397189736366272\n",
      "0.3088606297969818\n",
      "0.43234172463417053\n",
      "0.31883504986763\n",
      "0.47825613617897034\n",
      "0.31273922324180603\n",
      "0.22254182398319244\n",
      "0.1890438348054886\n",
      "0.0885474756360054\n",
      "0.2200123816728592\n",
      "0.5069555640220642\n",
      "0.20299282670021057\n",
      "0.5870031714439392\n",
      "0.17916268110275269\n",
      "0.9937090277671814\n",
      "0.24981443583965302\n",
      "0.2966221272945404\n",
      "0.617771565914154\n",
      "0.2686989903450012\n",
      "0.3767421245574951\n",
      "2.0734353065490723\n",
      "2.0734353065490723\n",
      "0.38427701592445374\n",
      "0.45798930525779724\n",
      "0.2993377149105072\n",
      "0.28939300775527954\n",
      "0.10180415958166122\n",
      "0.38395068049430847\n",
      "0.49687477946281433\n",
      "0.5143312811851501\n",
      "0.5334572196006775\n",
      "0.2842097580432892\n",
      "0.17854735255241394\n",
      "0.12126480787992477\n",
      "0.33600541949272156\n",
      "0.5439078211784363\n",
      "0.785343587398529\n",
      "0.895272433757782\n",
      "0.8249005079269409\n",
      "0.587882399559021\n",
      "0.5395386815071106\n",
      "0.9256495833396912\n",
      "0.6543086767196655\n",
      "0.6615603566169739\n",
      "0.5450343489646912\n",
      "0.6395642161369324\n",
      "0.2760305404663086\n",
      "0.2744048535823822\n",
      "0.5243661403656006\n",
      "0.3267472982406616\n",
      "0.5086626410484314\n",
      "0.44114261865615845\n",
      "1.4509305953979492\n",
      "1.4509305953979492\n",
      "0.3107658326625824\n",
      "0.1830528825521469\n",
      "0.268323689699173\n",
      "0.2024572640657425\n",
      "0.37070342898368835\n",
      "0.5922110080718994\n",
      "0.6963748335838318\n",
      "0.631228506565094\n",
      "0.4164527356624603\n",
      "0.347991406917572\n",
      "0.1647031456232071\n",
      "0.2611691951751709\n",
      "0.36268147826194763\n",
      "0.4188649654388428\n",
      "0.5060811638832092\n",
      "0.2517271041870117\n",
      "0.21233075857162476\n",
      "0.09865535795688629\n",
      "0.7214294075965881\n",
      "0.5430522561073303\n",
      "0.1604129821062088\n",
      "0.6321441531181335\n",
      "0.588769793510437\n",
      "0.8546706438064575\n",
      "0.35048162937164307\n",
      "0.3913145363330841\n",
      "0.7087156176567078\n",
      "0.32603469491004944\n",
      "0.35011279582977295\n",
      "0.43786516785621643\n",
      "0.07237926125526428\n",
      "0.4724261462688446\n",
      "0.6383836269378662\n",
      "0.9370445013046265\n",
      "0.9866322875022888\n",
      "0.4525809586048126\n",
      "0.7783601880073547\n",
      "0.8021869659423828\n",
      "0.5994073748588562\n",
      "0.858479380607605\n",
      "0.4646390378475189\n",
      "1.3125313520431519\n",
      "1.3125313520431519\n",
      "0.3652673661708832\n",
      "0.33318662643432617\n",
      "0.45557481050491333\n",
      "0.22444677352905273\n",
      "0.3342794179916382\n",
      "0.1691862791776657\n",
      "0.4560064375400543\n",
      "0.08729875832796097\n",
      "0.40591108798980713\n",
      "0.4124370813369751\n",
      "0.4616875946521759\n",
      "0.480195552110672\n",
      "0.2345198541879654\n",
      "0.35121387243270874\n",
      "0.47947636246681213\n",
      "0.398855984210968\n",
      "0.29091382026672363\n",
      "0.25173982977867126\n",
      "0.18803992867469788\n",
      "0.22888411581516266\n",
      "0.07313726842403412\n",
      "0.16217607259750366\n",
      "0.5226531028747559\n",
      "0.10094749182462692\n",
      "0.29631051421165466\n",
      "0.33050432801246643\n",
      "0.2521921992301941\n",
      "0.5678655505180359\n",
      "0.40688490867614746\n",
      "0.29602816700935364\n",
      "0.1581154316663742\n",
      "0.5042441487312317\n",
      "0.3805127441883087\n",
      "0.34448015689849854\n",
      "0.12731419503688812\n",
      "0.2588706910610199\n",
      "0.4370492100715637\n",
      "0.28369295597076416\n",
      "0.13686934113502502\n",
      "0.5527291893959045\n",
      "0.9095894694328308\n",
      "0.4700922966003418\n",
      "0.2806550860404968\n",
      "0.41579127311706543\n",
      "0.6083734631538391\n",
      "1.3489021062850952\n",
      "1.3489021062850952\n",
      "0.38388487696647644\n",
      "0.2502622604370117\n",
      "0.3901999592781067\n",
      "0.24150557816028595\n",
      "0.43401026725769043\n",
      "0.4822751581668854\n",
      "0.19023174047470093\n",
      "0.4111577570438385\n",
      "0.48000308871269226\n",
      "0.9128007888793945\n",
      "0.9947231411933899\n",
      "0.9594638347625732\n",
      "0.8191307783126831\n",
      "0.788963794708252\n",
      "0.46462759375572205\n",
      "0.8245784640312195\n",
      "0.9484768509864807\n",
      "0.6272264122962952\n",
      "1.001235008239746\n",
      "1.5555825233459473\n",
      "1.5555825233459473\n",
      "0.39836791157722473\n",
      "0.25242578983306885\n",
      "0.2918586730957031\n",
      "0.3194733262062073\n",
      "0.229429230093956\n",
      "0.28421151638031006\n",
      "0.3674561381340027\n",
      "0.5539187788963318\n",
      "0.14696909487247467\n",
      "0.21335022151470184\n",
      "0.10821117460727692\n",
      "0.2526373863220215\n",
      "0.5539896488189697\n",
      "0.6892517805099487\n",
      "0.4495208263397217\n",
      "0.4063914120197296\n",
      "0.7458205819129944\n",
      "0.6843743324279785\n",
      "0.8040011525154114\n",
      "0.6948472261428833\n",
      "0.486829549074173\n",
      "0.45332396030426025\n",
      "0.7146140933036804\n",
      "0.5412262678146362\n",
      "0.7247253656387329\n",
      "0.20567885041236877\n",
      "0.3388579785823822\n",
      "0.5743857026100159\n",
      "0.7038754224777222\n",
      "0.742320716381073\n",
      "0.3344690203666687\n",
      "0.43828850984573364\n",
      "0.5153658390045166\n",
      "0.1200035959482193\n",
      "0.6684432029724121\n",
      "0.8399757146835327\n",
      "0.6095277667045593\n",
      "0.6496021747589111\n",
      "0.6740937829017639\n",
      "0.7682194113731384\n",
      "0.7413631081581116\n",
      "0.7750592827796936\n",
      "0.688404381275177\n",
      "0.7519225478172302\n",
      "0.6812243461608887\n",
      "0.6576743721961975\n",
      "0.41642919182777405\n",
      "0.7948116064071655\n",
      "0.7081131339073181\n",
      "0.6541345119476318\n",
      "0.88774573802948\n",
      "0.3434019386768341\n",
      "1.1048539876937866\n",
      "1.1048539876937866\n",
      "0.08386201411485672\n",
      "0.36144158244132996\n",
      "0.5030444264411926\n",
      "0.6992986798286438\n",
      "0.8237341642379761\n",
      "0.4737975001335144\n",
      "0.29263079166412354\n",
      "0.15348581969738007\n",
      "0.33924317359924316\n",
      "0.5152422785758972\n",
      "0.39894598722457886\n",
      "0.8545390367507935\n",
      "0.6412096619606018\n",
      "0.5547083616256714\n",
      "0.37103208899497986\n",
      "0.48472774028778076\n",
      "0.2141285389661789\n",
      "0.3601199984550476\n",
      "0.6249426007270813\n",
      "0.5581024289131165\n",
      "0.3067209720611572\n",
      "0.28131332993507385\n",
      "0.8249616622924805\n",
      "0.8372622132301331\n",
      "1.5664842128753662\n",
      "0.2307371348142624\n",
      "0.2529980540275574\n",
      "0.14520972967147827\n",
      "0.40009474754333496\n",
      "0.45703059434890747\n",
      "0.2600894868373871\n",
      "0.09791775792837143\n",
      "0.5115223526954651\n",
      "0.6421000361442566\n",
      "0.15306377410888672\n",
      "0.27019134163856506\n",
      "0.3152511417865753\n",
      "0.24751311540603638\n",
      "0.3718879222869873\n",
      "0.3256170153617859\n",
      "0.2266140878200531\n",
      "0.10098955035209656\n",
      "0.6275931000709534\n",
      "0.5234041810035706\n",
      "0.6271852254867554\n",
      "0.3531572222709656\n",
      "0.383020281791687\n",
      "0.49631085991859436\n",
      "0.09198155999183655\n",
      "0.08751701563596725\n",
      "0.3743010461330414\n",
      "0.459359347820282\n",
      "0.2836131155490875\n",
      "0.18885724246501923\n",
      "0.38761481642723083\n",
      "0.5360404253005981\n",
      "0.3655673861503601\n",
      "0.3277835249900818\n",
      "0.639075517654419\n",
      "0.38626426458358765\n",
      "0.6431928873062134\n",
      "0.7009727358818054\n",
      "0.6751368641853333\n",
      "0.38372695446014404\n",
      "0.30434373021125793\n",
      "0.3264455199241638\n",
      "0.5351136922836304\n",
      "0.14930899441242218\n",
      "0.5629992485046387\n",
      "0.43109625577926636\n",
      "0.2873092293739319\n",
      "0.6041170954704285\n",
      "0.3233156204223633\n",
      "0.24680592119693756\n",
      "0.24943862855434418\n",
      "0.10912597179412842\n",
      "0.4443577229976654\n",
      "0.32255858182907104\n",
      "0.4871045649051666\n",
      "0.2658277451992035\n",
      "0.2012791633605957\n",
      "0.2676202058792114\n",
      "0.11298166960477829\n",
      "0.37944459915161133\n",
      "0.6690001487731934\n",
      "0.4166509211063385\n",
      "0.9024879336357117\n",
      "0.6552831530570984\n",
      "0.6583676934242249\n",
      "0.599155604839325\n",
      "0.9155594706535339\n",
      "0.7457789778709412\n",
      "0.9496685862541199\n",
      "1.050540804862976\n",
      "0.6329872608184814\n",
      "0.07946499437093735\n",
      "0.48219946026802063\n",
      "0.8135387897491455\n",
      "0.8323260545730591\n",
      "0.399829238653183\n",
      "0.24747954308986664\n",
      "0.6577199101448059\n",
      "1.1968094110488892\n",
      "0.5138532519340515\n",
      "1.02942955493927\n",
      "1.650626301765442\n",
      "0.1748267412185669\n",
      "0.30430498719215393\n",
      "0.14265857636928558\n",
      "0.16324760019779205\n",
      "0.3821663558483124\n",
      "0.5387964844703674\n",
      "0.30868589878082275\n",
      "0.52311772108078\n",
      "0.3672802746295929\n",
      "0.5199276804924011\n",
      "0.45301738381385803\n",
      "0.41246289014816284\n",
      "0.3453536033630371\n",
      "0.32524374127388\n",
      "0.5939558148384094\n",
      "0.39866903424263\n",
      "0.5950718522071838\n",
      "0.2839718461036682\n",
      "0.6276472210884094\n",
      "0.41202205419540405\n",
      "0.6753467917442322\n",
      "0.5058310031890869\n",
      "1.566041111946106\n",
      "1.566041111946106\n",
      "0.4647805690765381\n",
      "0.36967042088508606\n",
      "0.27269455790519714\n",
      "0.3765776753425598\n",
      "0.29102978110313416\n",
      "0.103159599006176\n",
      "0.230835422873497\n",
      "0.3307264745235443\n",
      "0.34074077010154724\n",
      "0.30467668175697327\n",
      "0.37321922183036804\n",
      "0.3539971709251404\n",
      "0.3409600555896759\n",
      "0.5534459352493286\n",
      "0.22455477714538574\n",
      "0.4487389326095581\n",
      "0.6974327564239502\n",
      "0.08835183084011078\n",
      "0.13881908357143402\n",
      "0.4756201505661011\n",
      "0.5473242998123169\n",
      "0.15948790311813354\n",
      "0.2638811767101288\n",
      "0.3244379162788391\n",
      "0.28248387575149536\n",
      "1.5668257474899292\n",
      "0.27644386887550354\n",
      "0.17971262335777283\n",
      "0.2679072320461273\n",
      "0.08285674452781677\n",
      "0.3573671281337738\n",
      "0.39848417043685913\n",
      "0.2887703478336334\n",
      "0.19901296496391296\n",
      "0.4203813076019287\n",
      "0.2305671125650406\n",
      "0.22517669200897217\n",
      "0.24495308101177216\n",
      "0.149955615401268\n",
      "0.46775126457214355\n",
      "0.4359188973903656\n",
      "0.632016658782959\n",
      "0.7097825407981873\n",
      "0.3944661021232605\n",
      "0.2527689039707184\n",
      "0.49398672580718994\n",
      "0.46474266052246094\n",
      "0.41715922951698303\n",
      "0.2502584755420685\n",
      "0.4376646876335144\n",
      "0.12678425014019012\n",
      "0.269594669342041\n",
      "0.42665258049964905\n",
      "1.0555474758148193\n",
      "0.4296334385871887\n",
      "0.4400714933872223\n",
      "0.4842210114002228\n",
      "0.3815348446369171\n",
      "0.33532702922821045\n",
      "0.3084408938884735\n",
      "0.24940109252929688\n",
      "0.32725799083709717\n",
      "0.45430612564086914\n",
      "0.22022369503974915\n",
      "0.2986588478088379\n",
      "0.24057945609092712\n",
      "0.08019375801086426\n",
      "0.19235363602638245\n",
      "0.1605326235294342\n",
      "0.3994046151638031\n",
      "0.07750469446182251\n",
      "0.3440403938293457\n",
      "0.3360452353954315\n",
      "0.3095465302467346\n",
      "0.5557547807693481\n",
      "0.6424745917320251\n",
      "0.5898935794830322\n",
      "0.7366959452629089\n",
      "0.44528746604919434\n",
      "0.3826444447040558\n",
      "0.5132579207420349\n",
      "0.3622085750102997\n",
      "0.8249378800392151\n",
      "0.4663429260253906\n",
      "0.47023719549179077\n",
      "0.449690580368042\n",
      "0.34751302003860474\n",
      "0.3508980870246887\n",
      "0.1704634726047516\n",
      "0.43044644594192505\n",
      "0.5437173247337341\n",
      "0.6601257920265198\n",
      "0.5491523146629333\n",
      "0.07004368305206299\n",
      "0.5388527512550354\n",
      "0.21246516704559326\n",
      "0.3457356095314026\n",
      "0.1372339278459549\n",
      "0.2486090213060379\n",
      "0.13675053417682648\n",
      "0.3785194158554077\n",
      "0.193398579955101\n",
      "0.08683761954307556\n",
      "0.4689856171607971\n",
      "0.2497609704732895\n",
      "0.25360435247421265\n",
      "0.4151086211204529\n",
      "0.35314103960990906\n",
      "0.47629666328430176\n",
      "0.3509117364883423\n",
      "0.5016159415245056\n",
      "0.7685831189155579\n",
      "0.16420476138591766\n",
      "0.5963871479034424\n",
      "0.5645659565925598\n",
      "0.21545611321926117\n",
      "0.25541621446609497\n",
      "0.6133453845977783\n",
      "0.36213889718055725\n",
      "0.4367366433143616\n",
      "0.47302961349487305\n",
      "0.8698397278785706\n",
      "0.6736626029014587\n",
      "0.7610710263252258\n",
      "0.4208031892776489\n",
      "0.44905591011047363\n",
      "0.3888660669326782\n",
      "1.5643396377563477\n",
      "1.5643396377563477\n",
      "0.10325224697589874\n",
      "0.3091496527194977\n",
      "0.42878907918930054\n",
      "0.43955332040786743\n",
      "0.18112903833389282\n",
      "0.37527480721473694\n",
      "0.4649110734462738\n",
      "0.4563048183917999\n",
      "0.20208798348903656\n",
      "0.4264185428619385\n",
      "0.12425897270441055\n",
      "0.24430812895298004\n",
      "0.14252309501171112\n",
      "0.15514282882213593\n",
      "0.23424270749092102\n",
      "0.2823958098888397\n",
      "0.2582651674747467\n",
      "0.37686687707901\n",
      "0.4285544455051422\n",
      "0.6846362352371216\n",
      "0.5322141051292419\n",
      "0.49093806743621826\n",
      "0.6445774435997009\n",
      "0.31378352642059326\n",
      "0.18241576850414276\n",
      "0.24525021016597748\n",
      "0.07937247306108475\n",
      "0.4629252851009369\n",
      "0.5469154119491577\n",
      "0.3800916373729706\n",
      "0.736770749092102\n",
      "0.4911763668060303\n",
      "0.6102349162101746\n",
      "0.9407546520233154\n",
      "0.9950478076934814\n",
      "1.6886184215545654\n",
      "1.6886184215545654\n",
      "0.23697084188461304\n",
      "0.2333642691373825\n",
      "0.16002793610095978\n",
      "0.44826164841651917\n",
      "0.1238771304488182\n",
      "0.2093966007232666\n",
      "0.2348802238702774\n",
      "0.10255325585603714\n",
      "0.1988483965396881\n",
      "0.41009896993637085\n",
      "0.5412170886993408\n",
      "0.47880151867866516\n",
      "0.357065349817276\n",
      "0.3268924951553345\n",
      "0.6317064762115479\n",
      "0.6161043047904968\n",
      "0.21672415733337402\n",
      "0.13423876464366913\n",
      "0.40852269530296326\n",
      "0.4897387623786926\n",
      "0.23890139162540436\n",
      "0.4139479100704193\n",
      "0.45521363615989685\n",
      "0.4510330259799957\n",
      "0.6010456681251526\n",
      "0.5117375254631042\n",
      "0.7378785014152527\n",
      "0.740376889705658\n",
      "0.729910135269165\n",
      "0.30074021220207214\n",
      "0.08152489364147186\n",
      "0.41930708289146423\n",
      "0.2959862947463989\n",
      "0.2912159264087677\n",
      "0.3707946240901947\n",
      "0.17992478609085083\n",
      "0.26454177498817444\n",
      "0.5899863243103027\n",
      "0.3997608423233032\n",
      "0.5928928852081299\n",
      "0.4323667883872986\n",
      "0.8494645953178406\n",
      "0.32467028498649597\n",
      "0.23025453090667725\n",
      "0.17898595333099365\n",
      "0.16434426605701447\n",
      "0.2429271787405014\n",
      "0.38251692056655884\n",
      "0.5071529746055603\n",
      "0.4324982464313507\n",
      "0.3094411790370941\n",
      "0.23665130138397217\n",
      "0.6568672060966492\n",
      "0.23533573746681213\n",
      "0.5381788611412048\n",
      "0.765662670135498\n",
      "0.18086326122283936\n",
      "1.96209716796875\n",
      "0.13434705138206482\n",
      "0.40165188908576965\n",
      "0.39630499482154846\n",
      "0.3408249020576477\n",
      "0.35026323795318604\n",
      "0.46687138080596924\n",
      "0.41834941506385803\n",
      "0.3072746694087982\n",
      "0.29824596643447876\n",
      "0.1973934769630432\n",
      "0.371675580739975\n",
      "0.2922056019306183\n",
      "0.1795443445444107\n",
      "0.20344600081443787\n",
      "0.49108582735061646\n",
      "0.6037771105766296\n",
      "0.41260242462158203\n",
      "0.21916286647319794\n",
      "0.24104641377925873\n",
      "0.5355651378631592\n",
      "0.24506650865077972\n",
      "0.29458606243133545\n",
      "0.48846349120140076\n",
      "0.1579754799604416\n",
      "0.21956461668014526\n",
      "0.22103196382522583\n",
      "0.11229258030653\n",
      "0.3887593150138855\n",
      "0.45649775862693787\n",
      "0.1633225381374359\n",
      "0.2788238525390625\n",
      "0.40717220306396484\n",
      "0.20154207944869995\n",
      "0.24045054614543915\n",
      "0.25420644879341125\n",
      "0.10713256895542145\n",
      "0.16897575557231903\n",
      "0.3809354603290558\n",
      "0.4641817808151245\n",
      "0.2701139748096466\n",
      "0.10972733795642853\n",
      "0.2025229036808014\n",
      "0.2515476644039154\n",
      "0.2203020453453064\n",
      "0.3552926480770111\n",
      "0.39279380440711975\n",
      "0.6628056168556213\n",
      "0.23606623709201813\n",
      "0.17780372500419617\n",
      "0.3594943583011627\n",
      "0.3019291162490845\n",
      "0.4040384590625763\n",
      "0.23238714039325714\n",
      "0.267636239528656\n",
      "0.35404691100120544\n",
      "0.4660760760307312\n",
      "0.13122911751270294\n",
      "0.17676261067390442\n",
      "0.3266044855117798\n",
      "0.36066165566444397\n",
      "0.26176315546035767\n",
      "0.13479305803775787\n",
      "0.3786996603012085\n",
      "0.16302840411663055\n",
      "0.34043335914611816\n",
      "0.4551304578781128\n",
      "0.5087491869926453\n",
      "0.6629593372344971\n",
      "0.384184330701828\n",
      "0.6232456564903259\n",
      "0.2439173460006714\n",
      "0.7148827314376831\n",
      "0.4130445420742035\n",
      "0.35734155774116516\n",
      "0.9869828820228577\n",
      "0.9284306764602661\n",
      "1.3654226064682007\n",
      "1.3654226064682007\n",
      "0.4075451195240021\n",
      "0.31683972477912903\n",
      "0.1660178154706955\n",
      "0.31582167744636536\n",
      "0.40413999557495117\n",
      "0.2707468271255493\n",
      "0.3812755048274994\n",
      "0.3352511525154114\n",
      "0.2627006769180298\n",
      "0.21731337904930115\n",
      "0.16868752241134644\n",
      "0.22671663761138916\n",
      "0.3468475341796875\n",
      "0.09557979553937912\n",
      "0.4655607342720032\n",
      "0.21262824535369873\n",
      "0.5696384310722351\n",
      "0.5291772484779358\n",
      "0.3105057179927826\n",
      "0.1457795947790146\n",
      "0.29585567116737366\n",
      "0.23854658007621765\n",
      "0.36816197633743286\n",
      "0.38883841037750244\n",
      "0.3245699405670166\n",
      "0.3246074318885803\n",
      "0.6360083818435669\n",
      "0.6026274561882019\n",
      "0.48031067848205566\n",
      "0.35135653614997864\n",
      "0.27897197008132935\n",
      "0.3369831144809723\n",
      "0.3829974830150604\n",
      "0.39730557799339294\n",
      "0.5003803968429565\n",
      "0.23703190684318542\n",
      "0.25824540853500366\n",
      "0.0755976065993309\n",
      "0.14992520213127136\n",
      "0.3716772496700287\n",
      "0.3067343235015869\n",
      "0.21156299114227295\n",
      "0.18346364796161652\n",
      "0.13289545476436615\n",
      "0.5981411337852478\n",
      "0.36911752820014954\n",
      "0.16380085051059723\n",
      "0.44896388053894043\n",
      "0.13108600676059723\n",
      "0.34172922372817993\n",
      "0.11789017170667648\n",
      "0.30061426758766174\n",
      "0.331216961145401\n",
      "0.22054331004619598\n",
      "0.5528538227081299\n",
      "0.19917899370193481\n",
      "0.0655084177851677\n",
      "0.46487104892730713\n",
      "0.5525345802307129\n",
      "0.5615260004997253\n",
      "0.9144842028617859\n",
      "0.7110673189163208\n",
      "0.3055514693260193\n",
      "0.3815929591655731\n",
      "0.20204436779022217\n",
      "0.28553175926208496\n",
      "0.06371782720088959\n",
      "0.22073501348495483\n",
      "0.18277697265148163\n",
      "0.29025769233703613\n",
      "0.5519909858703613\n",
      "0.2502939701080322\n",
      "0.19697290658950806\n",
      "0.247291699051857\n",
      "0.1867230236530304\n",
      "0.1274750828742981\n",
      "0.2261706441640854\n",
      "0.20191222429275513\n",
      "0.44411447644233704\n",
      "0.46607476472854614\n",
      "0.7128170728683472\n",
      "0.23260444402694702\n",
      "0.18726897239685059\n",
      "0.39500826597213745\n",
      "0.35723963379859924\n",
      "0.23794282972812653\n",
      "0.06842788308858871\n",
      "0.3312021493911743\n",
      "0.6407556533813477\n",
      "0.38026443123817444\n",
      "0.1939230114221573\n",
      "0.3222404420375824\n",
      "0.1876312494277954\n",
      "0.1489333212375641\n",
      "0.10016307234764099\n",
      "0.42778876423835754\n",
      "0.5281826257705688\n",
      "0.4711869955062866\n",
      "0.39704445004463196\n",
      "0.4531314969062805\n",
      "0.6563759446144104\n",
      "0.6293144822120667\n",
      "0.2561399042606354\n",
      "0.9819901585578918\n",
      "0.3769003450870514\n",
      "0.21321532130241394\n",
      "0.3433985114097595\n",
      "0.17615820467472076\n",
      "0.13102875649929047\n",
      "0.2822706699371338\n",
      "0.48519718647003174\n",
      "0.36340203881263733\n",
      "0.38573846220970154\n",
      "0.8203367590904236\n",
      "0.7589481472969055\n",
      "0.4964101314544678\n",
      "0.4370116889476776\n",
      "0.3839612305164337\n",
      "0.20954665541648865\n",
      "0.2705909311771393\n",
      "0.4912797510623932\n",
      "0.41844481229782104\n",
      "0.40454185009002686\n",
      "0.4616699814796448\n",
      "0.15132717788219452\n",
      "0.11744113266468048\n",
      "0.18485158681869507\n",
      "0.2977962791919708\n",
      "0.20610491931438446\n",
      "0.3474525213241577\n",
      "0.10609742254018784\n",
      "0.7362136244773865\n",
      "0.10295818001031876\n",
      "0.4963162839412689\n",
      "0.22068478167057037\n",
      "0.4218263030052185\n",
      "0.12731772661209106\n",
      "0.34384238719940186\n",
      "0.33388960361480713\n",
      "0.44033071398735046\n",
      "0.7116932272911072\n",
      "0.957446277141571\n",
      "0.6125022172927856\n",
      "0.20220987498760223\n",
      "0.08517764508724213\n",
      "0.1323329508304596\n",
      "0.42972084879875183\n",
      "0.5061516165733337\n",
      "0.23734252154827118\n",
      "0.33356672525405884\n",
      "0.5991829633712769\n",
      "0.6453749537467957\n",
      "0.36987394094467163\n",
      "0.48443087935447693\n",
      "0.19158093631267548\n",
      "0.4236413240432739\n",
      "0.16202805936336517\n",
      "0.35812339186668396\n",
      "0.1915387511253357\n",
      "0.1996566653251648\n",
      "0.3392872214317322\n",
      "0.40402865409851074\n",
      "0.31455421447753906\n",
      "0.4753253161907196\n",
      "0.14565612375736237\n",
      "1.1957941055297852\n",
      "0.6484013199806213\n",
      "0.20685437321662903\n",
      "0.2055549919605255\n",
      "0.16790074110031128\n",
      "0.08459876477718353\n",
      "0.1619265377521515\n",
      "0.33148130774497986\n",
      "0.4450727105140686\n",
      "0.41053149104118347\n",
      "0.24554254114627838\n",
      "0.2663339674472809\n",
      "0.4701358377933502\n",
      "0.27536407113075256\n",
      "0.3618723452091217\n",
      "0.1405087262392044\n",
      "0.17480042576789856\n",
      "0.13781273365020752\n",
      "0.3493502736091614\n",
      "0.23507331311702728\n",
      "0.2590986490249634\n",
      "0.3097609281539917\n",
      "0.37639373540878296\n",
      "0.3566182255744934\n",
      "0.41307973861694336\n",
      "0.2875586152076721\n",
      "0.28739702701568604\n",
      "0.43676653504371643\n",
      "0.3815949559211731\n",
      "0.25019940733909607\n",
      "0.29227232933044434\n",
      "0.2732540965080261\n",
      "0.4232715368270874\n",
      "0.2385510355234146\n",
      "0.07853496074676514\n",
      "0.21337705850601196\n",
      "0.3530421257019043\n",
      "0.41293108463287354\n",
      "0.2473517805337906\n",
      "0.1785126030445099\n",
      "0.06812602281570435\n",
      "0.2965288460254669\n",
      "0.16733843088150024\n",
      "0.27437838912010193\n",
      "0.3830811679363251\n",
      "0.5977487564086914\n",
      "0.29584890604019165\n",
      "0.11500151455402374\n",
      "0.22022035717964172\n",
      "0.20422020554542542\n",
      "0.48899146914482117\n",
      "0.4036848843097687\n",
      "0.39314982295036316\n",
      "0.7222859859466553\n",
      "0.4820203185081482\n",
      "0.28719785809516907\n",
      "0.27449947595596313\n",
      "0.0805022120475769\n",
      "0.5310734510421753\n",
      "0.1567763090133667\n",
      "0.4045214354991913\n",
      "0.06418164819478989\n",
      "0.3493489623069763\n",
      "0.3969849646091461\n",
      "0.548153817653656\n",
      "0.5716803669929504\n",
      "0.3081216514110565\n",
      "0.10938713699579239\n",
      "0.1492202877998352\n",
      "0.21130971610546112\n",
      "0.08945204317569733\n",
      "0.16636210680007935\n",
      "0.17633704841136932\n",
      "0.3558766841888428\n",
      "0.2926376760005951\n",
      "0.5395110249519348\n",
      "0.6141581535339355\n",
      "0.1165333017706871\n",
      "0.08942021429538727\n",
      "0.4388156235218048\n",
      "0.11697853356599808\n",
      "0.2298172116279602\n",
      "0.3159467279911041\n",
      "0.15661488473415375\n",
      "0.22182048857212067\n",
      "0.29777655005455017\n",
      "0.46957653760910034\n",
      "0.35629284381866455\n",
      "0.21545571088790894\n",
      "0.2649047374725342\n",
      "0.1383931189775467\n",
      "0.43700000643730164\n",
      "0.3313080668449402\n",
      "0.4592084288597107\n",
      "0.2562253773212433\n",
      "0.5256245732307434\n",
      "0.19583085179328918\n",
      "0.16446951031684875\n",
      "0.15759237110614777\n",
      "0.2165258526802063\n",
      "0.4514937400817871\n",
      "0.1606006622314453\n",
      "0.06680448353290558\n",
      "0.2853510081768036\n",
      "0.7223963737487793\n",
      "0.5522449612617493\n",
      "0.6540550589561462\n",
      "0.23617005348205566\n",
      "0.14574989676475525\n",
      "0.35761427879333496\n",
      "0.11986684054136276\n",
      "0.15640221536159515\n",
      "0.1855146884918213\n",
      "0.2234681248664856\n",
      "0.3074609339237213\n",
      "0.5024682879447937\n",
      "0.46898531913757324\n",
      "0.43453913927078247\n",
      "0.3032415211200714\n",
      "0.2993060052394867\n",
      "0.20823217928409576\n",
      "0.16285313665866852\n",
      "0.344186931848526\n",
      "0.1689308136701584\n",
      "0.291922390460968\n",
      "0.620244026184082\n",
      "0.49392080307006836\n",
      "0.31586578488349915\n",
      "0.3221662938594818\n",
      "0.20428115129470825\n",
      "0.13236229121685028\n",
      "0.10983558744192123\n",
      "0.3039964437484741\n",
      "0.3519900441169739\n",
      "0.207804337143898\n",
      "0.4675983786582947\n",
      "0.17522060871124268\n",
      "0.4280799925327301\n",
      "0.2675301730632782\n",
      "0.10288131982088089\n",
      "0.3642573356628418\n",
      "0.36904850602149963\n",
      "0.1529347449541092\n",
      "0.3572138547897339\n",
      "0.3071499466896057\n",
      "0.5766882300376892\n",
      "0.7717117071151733\n",
      "0.6577325463294983\n",
      "0.45699161291122437\n",
      "0.20173147320747375\n",
      "0.32896652817726135\n",
      "0.2971946597099304\n",
      "0.16069239377975464\n",
      "0.5009434819221497\n",
      "0.22419841587543488\n",
      "0.07752633094787598\n",
      "0.31351882219314575\n",
      "0.4254053235054016\n",
      "0.4843377470970154\n",
      "0.22040154039859772\n",
      "0.3604375123977661\n",
      "0.17369236052036285\n",
      "0.36416399478912354\n",
      "0.1067214086651802\n",
      "0.08536206185817719\n",
      "0.4154057204723358\n",
      "0.7243995070457458\n",
      "0.49195653200149536\n",
      "0.6576310992240906\n",
      "0.2125897854566574\n",
      "0.208296000957489\n",
      "0.3864611089229584\n",
      "0.39213827252388\n",
      "0.27223727107048035\n",
      "0.47136104106903076\n",
      "0.10232750326395035\n",
      "0.3278855085372925\n",
      "0.16393770277500153\n",
      "0.3917877674102783\n",
      "0.19400279223918915\n",
      "0.39806899428367615\n",
      "0.39850369095802307\n",
      "0.18393246829509735\n",
      "0.10307502746582031\n",
      "0.1489931344985962\n",
      "0.20021477341651917\n",
      "0.6815152168273926\n",
      "0.37123915553092957\n",
      "0.5153366923332214\n",
      "0.3352717459201813\n",
      "0.299448162317276\n",
      "0.25472816824913025\n",
      "0.2947094738483429\n",
      "0.41484880447387695\n",
      "0.31084829568862915\n",
      "0.13410750031471252\n",
      "0.38938793540000916\n",
      "0.15415751934051514\n",
      "0.20317170023918152\n",
      "0.14997132122516632\n",
      "0.13949520885944366\n",
      "0.21282042562961578\n",
      "0.09550655633211136\n",
      "0.2782410681247711\n",
      "0.48062700033187866\n",
      "0.36003267765045166\n",
      "0.36109358072280884\n",
      "0.5982252359390259\n",
      "0.1669384092092514\n",
      "0.2168956845998764\n",
      "0.22491773962974548\n",
      "0.19112128019332886\n",
      "0.1317378133535385\n",
      "0.2961028814315796\n",
      "0.3410482704639435\n",
      "0.41820043325424194\n",
      "0.35500404238700867\n",
      "0.30721089243888855\n",
      "0.3224184811115265\n",
      "0.46511974930763245\n",
      "0.25199899077415466\n",
      "0.3700081706047058\n",
      "0.38775941729545593\n",
      "0.2058175802230835\n",
      "0.1980021595954895\n",
      "0.2842773497104645\n",
      "0.43562859296798706\n",
      "0.5978177189826965\n",
      "0.45327427983283997\n",
      "0.16617286205291748\n",
      "0.06462414562702179\n",
      "0.14591899514198303\n",
      "0.3032364249229431\n",
      "0.06579453498125076\n",
      "0.46613579988479614\n",
      "0.2649248242378235\n",
      "0.16988514363765717\n",
      "0.5108395218849182\n",
      "0.11627258360385895\n",
      "0.1909925490617752\n",
      "0.2687355875968933\n",
      "0.3474735915660858\n",
      "0.5032426118850708\n",
      "0.1822376698255539\n",
      "0.1592024564743042\n",
      "0.48854997754096985\n",
      "0.32234320044517517\n",
      "0.5858774185180664\n",
      "0.7401793599128723\n",
      "0.2542100250720978\n",
      "0.22635865211486816\n",
      "0.08684965968132019\n",
      "0.39541327953338623\n",
      "0.4751332998275757\n",
      "0.3786752223968506\n",
      "0.5165005326271057\n",
      "0.2107670158147812\n",
      "0.3352619707584381\n",
      "0.2302786260843277\n",
      "0.3693157732486725\n",
      "0.10666358470916748\n",
      "0.08979316055774689\n",
      "0.13740360736846924\n",
      "0.27461421489715576\n",
      "0.6487894654273987\n",
      "0.5808280110359192\n",
      "0.3632931113243103\n",
      "0.7943268418312073\n",
      "0.2862047255039215\n",
      "0.17673048377037048\n",
      "0.5268663167953491\n",
      "0.30650830268859863\n",
      "0.7294575572013855\n",
      "0.8965288400650024\n",
      "0.1042635440826416\n",
      "0.5217581391334534\n",
      "0.5491905808448792\n",
      "0.3465684652328491\n",
      "0.25595515966415405\n",
      "0.12339482456445694\n",
      "0.3612214922904968\n",
      "0.2918976843357086\n",
      "0.2843030095100403\n",
      "0.3616337478160858\n",
      "0.2683793008327484\n",
      "0.34673449397087097\n",
      "0.31517302989959717\n",
      "0.12451271712779999\n",
      "0.2837313115596771\n",
      "0.2290855348110199\n",
      "0.24769523739814758\n",
      "0.16202136874198914\n",
      "0.31161922216415405\n",
      "0.3439965546131134\n",
      "0.8981636166572571\n",
      "0.14915570616722107\n",
      "0.16486603021621704\n",
      "0.321146160364151\n",
      "0.36704984307289124\n",
      "0.24716386198997498\n",
      "0.38881757855415344\n",
      "0.35629013180732727\n",
      "0.4924185872077942\n",
      "0.35600200295448303\n",
      "0.2867445945739746\n",
      "0.6109350919723511\n",
      "0.16713178157806396\n",
      "0.20585554838180542\n",
      "0.2943790555000305\n",
      "0.22926372289657593\n",
      "0.16386128962039948\n",
      "0.24381637573242188\n",
      "0.2955852746963501\n",
      "0.49707815051078796\n",
      "0.22484491765499115\n",
      "0.35719579458236694\n",
      "0.46161848306655884\n",
      "0.2655300498008728\n",
      "0.2891833484172821\n",
      "0.28657209873199463\n",
      "0.11068417131900787\n",
      "0.3652099668979645\n",
      "0.13061214983463287\n",
      "0.18622688949108124\n",
      "0.15603318810462952\n",
      "0.14222298562526703\n",
      "0.4229319095611572\n",
      "0.16539882123470306\n",
      "0.18693257868289948\n",
      "0.3885900378227234\n",
      "0.23222748935222626\n",
      "0.27527493238449097\n",
      "0.29775965213775635\n",
      "0.34771931171417236\n",
      "0.6942570209503174\n",
      "0.15373918414115906\n",
      "0.4847411811351776\n",
      "0.4766104519367218\n",
      "0.5345131754875183\n",
      "0.3080664575099945\n",
      "0.508521556854248\n",
      "0.339882493019104\n",
      "0.2516461908817291\n",
      "0.2361031174659729\n",
      "0.5491346716880798\n",
      "0.5406473875045776\n",
      "0.14833734929561615\n",
      "0.18263345956802368\n",
      "0.5093177556991577\n",
      "0.4559149742126465\n",
      "0.17907337844371796\n",
      "0.27201253175735474\n",
      "0.23333728313446045\n",
      "0.33921632170677185\n",
      "0.14490997791290283\n",
      "0.49675458669662476\n",
      "0.5354834794998169\n",
      "0.43594223260879517\n",
      "0.28681883215904236\n",
      "0.6260446906089783\n",
      "0.4645116925239563\n",
      "0.08159030973911285\n",
      "0.17082801461219788\n",
      "0.9958622455596924\n",
      "0.9501935839653015\n",
      "0.9196237325668335\n",
      "0.9686114192008972\n",
      "0.380203515291214\n",
      "0.40948331356048584\n",
      "0.7020832300186157\n",
      "0.5457178950309753\n",
      "0.35513025522232056\n",
      "0.4642435610294342\n",
      "0.41626885533332825\n",
      "0.15560290217399597\n",
      "0.7228325009346008\n",
      "0.5449011921882629\n",
      "0.7109549045562744\n",
      "0.6026685237884521\n",
      "0.49052828550338745\n",
      "0.5595324039459229\n",
      "0.4756283462047577\n",
      "0.35709521174430847\n",
      "0.3123394548892975\n",
      "0.7766534686088562\n",
      "0.37600064277648926\n",
      "0.25054582953453064\n",
      "0.8740963935852051\n",
      "0.38119304180145264\n",
      "0.33512499928474426\n",
      "0.5822351574897766\n",
      "0.31830090284347534\n",
      "0.6726003885269165\n",
      "0.718333899974823\n",
      "0.5463094115257263\n",
      "0.8407485485076904\n",
      "0.33603501319885254\n",
      "0.6617107391357422\n",
      "0.682047963142395\n",
      "0.4396400451660156\n",
      "0.17868784070014954\n",
      "0.4109122157096863\n",
      "0.45997154712677\n",
      "0.5226007103919983\n",
      "0.5474790334701538\n",
      "0.6731258034706116\n",
      "0.6638638973236084\n",
      "0.42069464921951294\n",
      "0.9541815519332886\n",
      "0.8201919794082642\n",
      "0.6362828612327576\n",
      "0.13564299046993256\n",
      "0.291648268699646\n",
      "0.7224153876304626\n",
      "0.7716158628463745\n",
      "2.218743085861206\n",
      "2.218743085861206\n",
      "0.3740418255329132\n",
      "0.1601426899433136\n",
      "0.458727091550827\n",
      "0.4296618103981018\n",
      "0.4588462710380554\n",
      "0.21747322380542755\n",
      "0.40716269612312317\n",
      "0.19409391283988953\n",
      "0.28872039914131165\n",
      "0.23835350573062897\n",
      "0.2036663442850113\n",
      "0.2048025280237198\n",
      "0.48102277517318726\n",
      "0.3142010271549225\n",
      "0.07377669215202332\n",
      "0.22291235625743866\n",
      "0.2572650909423828\n",
      "0.3724852502346039\n",
      "0.29387885332107544\n",
      "0.5520616769790649\n",
      "0.5306421518325806\n",
      "0.27566206455230713\n",
      "0.3313210606575012\n"
     ]
    }
   ],
   "source": [
    "e = 0\n",
    "while e <= agent.replay_buffer.tree.total():\n",
    "    print(agent.replay_buffer.tree.get(e)[1])\n",
    "    e += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb0468ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.99 + 0.01) ** 0.6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
